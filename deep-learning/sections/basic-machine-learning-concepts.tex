\section{Basic Machine Learning Concepts}

\subsection{Principles of Learning}

\subsubsection*{Learning from Data}
\begin{equation}
    y=f(x)+\epsilon
\end{equation}
\begin{itemize}
    \item $x=(x_1,x_2,\cdots,x_n)$: Input/feature/independent variable
    \item $y$: Output/response/dependent variable
    \item $\epsilon$: Noise / bias
    \item Main goal of machine learning: Estimate the unknown $F$ from data
\end{itemize}
\begin{figures}
    \fig{learning-from-data.png}{.5}
\end{figures}

\subsubsection*{How do we estimate $f$?}
\begin{itemize}
    \item All data is not available, ``sampled'' from population
    \item Estimate $f$ such that
    \begin{equation}
        y\approx\hat{f}(x)
    \end{equation}
    \item Training: Using data to teach a method to estimate $f$
    \item Parametric method
    \begin{itemize}
        \item Assume certain forms of $f$
        \item Find parameters that ``best'' approximates $y$
        \item More parameters, more flexibility
    \end{itemize}
    \item Estimating $f$ is important
    \begin{itemize}
        \item Make predictions of $y$ at new point $x=x_0$
        \item Understand how each component $x_i$ affects $y$
        \item Understand which component $x_i$ is important explaining $y$
    \end{itemize}
\end{itemize}

\subsubsection*{Classification and Regression}
\begin{itemize}
    \item Regression: Outputs are form of numerical quantity (often continuous)
    \item Categorical: Outputs are takes a value from classes
    \item Difference is not necessarily clear (e.g. logistic regression)
\end{itemize}

\subsubsection*{Linear Regression}
\begin{itemize}
    \item Linear explanation
    \begin{equation}
        b_i\approx\hat{f}(a_i;x)=x_0+x_1a_{i,1}+x_2a_{i,2}+\cdots+x_na_{i,n}=\tilde{a}_i^Tx
    \end{equation}
    \begin{itemize}
        \item Independent (explanatory, input) variable: $a_1,a_2,\cdots,a_m\in\mathbb{R}^n$
        \item Dependent (observation, output) variable: $b_1,b_2,\cdots,b_m$
        \item $x_0$: bias, $\tilde{a}_i=(1,a_i)$와 같이 parameter로 간주됨 $\Rightarrow$ Linear combination of $\mathbb{R}^{n+1}$
    \end{itemize}
    \item Objective: Minimize Loss function $L$
    \begin{equation}
        L(x)=\frac{1}{m}\sum_{i=1}^{m}\left(\hat{f}(a_i;x)-b_i\right)^2 = \frac{1}{m}\Vert Ax-b\Vert_2^2
    \end{equation}
    \begin{itemize}
        \item Mean Square Error (MSE), Adjust $x$ to minimize $L$
        \item Linear explanation $\hat{f}(a_i;x)=\tilde{a}_i^Tx$ $\Rightarrow$ Linear regression
        \item $\hat{f}(a_i;x)$: estimation, $b_i$: true explanation
    \end{itemize}
\end{itemize}

\subsection{Regularization}

\subsubsection*{Overfitting}
\begin{itemize}
    \item Consider a polynomial estimation $\hat{f}(a;x)=\sum_{i=0}^n\psi_i(a)x_i=\psi(a)^Tx$ where $\psi_i(a)=a^i$
    \item Suppose 10 samples (graphs below) in second-order polynomial relation
    \begin{itemize}
        \item Low order ($M=0,1$) does not fit the samples accurately
        \item Near order ($M=3$) represents the samples approximately
        \item High order ($M=9$) fits the samples perfectly, but does not represent the overall relation well
    \end{itemize}
    \begin{figures}
        \subfig{$M=0$}{overfitting-order-0.png}{.22}
        \subfig{$M=1$}{overfitting-order-1.png}{.22}
        \subfig{$M=3$}{overfitting-order-3.png}{.22}
        \subfig{$M=9$}{overfitting-order-9.png}{.22}
    \end{figures}
    \item Overfitting
    \begin{itemize}
        \item Sample에 지나치게 fit하는 model은 오히려 모집단의 성격을 나타내지 못할 수 있음
        \item Simple model (Low flexibility): Good interpretation, Bad accuracy
        \item Complex model (High flexibility): Good accuracy, Bad interpretation
    \end{itemize}
    \begin{figures}
        \subfig{X-Y graph}{flexibility-data.png}{.2256}
        \subfig{Flexibility-MSE}{flexibility-mse.png}{.2244}
    \end{figures}
    \item Test set
    \begin{itemize}
        \item Minimizing loss function of training set $\Rightarrow$ overfitting
        \item Validate the model with ``independent'' test dataset
        \item High flexibility $\Rightarrow$ $\mathrm{MSE_{Tr}}\to 0$, $\mathrm{MSE_{Te}}\to\infty$
    \end{itemize}
\end{itemize}

\subsubsection*{Regularization}
\begin{itemize}
    \item Method to supress overfitting
    \begin{itemize}
        \item Overfitting의 현상: Parameters $x$ becomes very large
        \item Idea: supress overfitting by minimizing $\Vert x\Vert$
    \end{itemize}
    \item Problem becomes solving two optimization problems
    \begin{itemize}
        \item minimize $\Vert Ax-b\Vert_2$: Data Loss
        \item minimize $\Vert x\Vert_2$: Regulation Loss
    \end{itemize}
    \item Ridge regression: Multi-objective optimization
    \begin{equation}\begin{aligned}
        \mathrm{minimize}~~&~~\Vert Ax-b\Vert_2^2+\lambda\Vert x\Vert_2^2
    \end{aligned}\end{equation}
    \begin{itemize}
        \item $\lambda>0$: hyperparameter; $\lambda\ll1$: Data loss 중시; $\lambda\gg1$: Regulation loss 중시
    \end{itemize}
    \begin{figures}
        \subfig{$\ln\lambda=-18$}{regularization-small-lambda.png}{.3}
        \subfig{$\ln\lambda=0$}{regularization-large-lambda.png}{.3}
    \end{figures}
    \item $L_1$ Regularization: Supress $x$ by by L1-norm
    \begin{equation}\begin{aligned}
        \mathrm{minimize}~~&~~\Vert Ax-b\Vert_2^2+\lambda\Vert x\Vert_1 \\ {}
    \end{aligned}~~~\Leftrightarrow~~~\begin{aligned}
        \mathrm{minimize}~~&~~\Vert Ax-b\Vert_2^2+\lambda\sum t_i \\
        \mathrm{subject~to}~~&~~t\succeq x,~t\succeq -x
    \end{aligned}\end{equation}
    \begin{itemize}
        \item Called Lasso
        \item Solution often has zero entries $\Rightarrow$ ``Sparse'' $x$ is oftenly obtained (Image below)
        \item Often used to approximate $L_0$ regularization ($\Vert x\Vert_0$: \# of nonzero elements in $x$; nonconvex)
    \end{itemize}
    \begin{figures}
        \subfig{L1-norm}{l1-norm.png}{.24}
        \subfig{L2-norm}{l2-norm.png}{.24}
    \end{figures}
\end{itemize}

\subsection{Logistic Regression and Binary Classification}

\subsubsection*{Logistic Regression}
\begin{itemize}
    \item Logistic regression provides \textbf{classifier}
    \begin{equation}\label{eq:dl:logistic-classifier}
        \mathbb{P}(b=1)=\sigma(a^Tx)=\frac{1}{1+\exp(-a^Tx)}
    \end{equation}
    \begin{itemize}
        \item Binary classification: output $b$ is either $0$(false) or $1$(true)
        \item $\hat{f}(a;x)\approx\mathbb{P}(b=1)$: probability of input $a$ is true($b=1$); $\mathcal{R}(\hat{f})=[0,1]$
        \item Obtain ``score'' from linear regression $a^Tx$; $\mathcal{R}(a^Tx)=(-\infty,\infty)$
        \item Large score $\Rightarrow$ $\mathrm{prob}\approx1$, small score $\Rightarrow$ $\mathrm{prob}\approx0$
        \item Use sigmoid function $\sigma(t)=\frac{1}{1+\exp(-t)}$ to normalize $(-\infty,\infty)\rightarrow[0,1]$
    \end{itemize}
    \begin{figures}
        \subfig{Logistic Regression}{logistic-regression.PNG}{.302}
        \subfig{Sigmoid Function}{sigmoid-function.PNG}{.328}
    \end{figures}
    \item Decision boundary($s$): 판단을 내리는 기준점
    \begin{itemize}
        \item $\sigma(x)>s$ $\Rightarrow$ true($1$), $\sigma(x)\leq s$ $\Rightarrow$ false($0$)
        \item $a^Tx=\sigma^{-1}(s)$, i.e. a hyperplane is a decision boundary
    \end{itemize}
    \item Interpretation
    \begin{itemize}
        \item We compare $\mathbb{P}(b=1|a)$ to $\mathbb{P}(b=0|a)$ to decide class
        \item From Bayes' rule,
        \begin{equation}
            \mathbb{P}(b=1|a)=\frac{\mathbb{P}(a|b=1)\mathbb{P}(b=1)}{\mathbb{P}(a)}=\frac{1}{1+\frac{\mathbb{P}(a|b=0)\mathbb{P}(b=0)}{\mathbb{P}(a|b=1)\mathbb{P}(b=1)}}
        \end{equation}
        \item $\mathbb{P}(a|b=k)=\mathbb{P}(a_1|b=k)\mathbb{P}(a_2|a_1,b=k)\cdots\mathbb{P}(a_n|a_1,\cdots,a_{n-1},n=k)$: Estimation is difficult
        \item Assume feature elements are mutually independent conditional on given label
        \item Na\"ive Bayes: $\mathbb{P}(a|b=k)=\prod_{i=1}^{n}\mathbb{P}(a_i|b=k)$
        \item Therefore,
        \begin{equation}
            \frac{\mathbb{P}(a|b=0)\mathbb{P}(b=0)}{\mathbb{P}(a|b=1)\mathbb{P}(b=1)}=\frac{\mathbb{P}(b=0)}{\mathbb{P}(b=1)}\prod_{i=1}^n\frac{\mathbb{P}(a_i|b=0)}{\mathbb{P}(a_i|b=1)}
        \end{equation}
        \item Modeling $\frac{\mathbb{P}(b=0)}{\mathbb{P}(b=1)}=\exp(-x_0)$, $\frac{\mathbb{P}(a_i|b=0)}{\mathbb{P}(a_i|b=1)}=\exp(-a_ix_i)$ gives \ref{eq:dl:logistic-classifier}
        \item Feature is Gaussian-distributed conditional $\Rightarrow$ exact expression
    \end{itemize}
\end{itemize}

\subsubsection*{Maximum Likelihood Estimation}
\begin{itemize}
    \item An example method determining $x$
    \item Consider Bernouli trials (e.g. biased coin toss) ($b$: result)
    \begin{itemize}
        \item $b=1$(true)일 확률이 $\theta$, $b=0$(false)일 확률이 $1-\theta$
        \item $b$를 observe할 확률: $\theta^b(1-\theta)^{1-b}$
        \item $m$번의 독립 시행으로 $b_1,b_2,\cdots,b_m\in\{0,1\}$을 관찰할 확률
        \begin{equation}
            \Lambda(\theta)=\prod_{i=1}^m\theta^{b_i}(1-\theta)^{1-b_i}
        \end{equation}
        \item $b=1$ 결과를 $k$회 관측 $\Rightarrow$ $\Lambda(\theta)=\theta^k(1-\theta)^{m-k}$
        \item Maximizing $\Lambda(\theta)$ is difficult; Maximize $\log\Lambda(\theta)$: log-likelihood $\Rightarrow$ $\theta^\ast=\frac{k}{m}$
    \end{itemize}
    \item Applying Logistic Regression
    \begin{itemize}
        \item Observed data: $(a_i,b_i)$ ($i=1,2,\cdots,m$)
        \item Likelihood of observing these data:
        \begin{equation}
            \Lambda(x)=\prod_{i=1}^m\sigma(a_i^Tx)^{b_i}\left(1-\sigma(a_i^Tx)\right)^{1-b_i}=\prod_{i=1}^m\frac{\left(\exp(a_i^Tx)\right)^{b_i}}{1+\exp(a_i^Tx)}
        \end{equation}
        \item Log-likelihood:
        \begin{equation}
            \log\Lambda(x)=-\sum_{i=1}^m\log\left(1+\exp(a_i^Tx)\right)+\sum_{i\in\{i|b_i=1\}}a_i^Tx
        \end{equation}
        \item Log-likelihood function is concave $\Rightarrow$ Convex optimization problem
        \item Maximizing likelihood $\Rightarrow$ Minimizing cross-entropy loss in deep models
    \end{itemize}
\end{itemize}

\subsection{Performance Metric}

\subsubsection*{Errors of Classifier}
\begin{itemize}
    \item Classifier may misjudge classes of test data
    \item Cases Naming
    \begin{itemize}
        \item Suppose classifier determines \cd{ground\_truth} as \cd{decision}
        \item Case name: \textbf{\cd{`\$\{ground\_truth === decision\} \$\{decision ? 'Positive' : 'Negative'\}`}}
    \end{itemize}
    \item True Positive (TP; hit): Determines True as True
    \item False Positive (FP; false alarm; Type I Error): Determines False as True
    \item False Negative (FN; missed dtection; Type II Error): Determines True as False
    \item True Negative (TN; correct rejection): Determines False as False
    \item Selected cases: Positive(decide as True) cases
    \item Relevant cases: True(ground truth) cases
\end{itemize}
\begin{figures}
    \subfig{Error Cases}{error-cases.png}{.2508}
    \subfig{Logistic Error Cases}{logistic-error-cases.eps}{.5492}
\end{figures}

\subsubsection*{Performance Metric}
\begin{itemize}
    \item Expresses performance of classifier
    \item Accuracy: Correct decisions
    \begin{equation}
        \text{accuracy}=\frac{\text{TP+TN}}{\text{TP+TN+FP+FN}}
    \end{equation}
    \begin{itemize}
        \item Small \# of relevant cases (class imbalance) $\Rightarrow$ 전부 False로 판별하면 accuracy는 높음
    \end{itemize}
    \item Recall(sensitivity): Selected among relevant cases; Positive 판별 능력
    \begin{equation}
        \text{recall}=\frac{\text{TP}}{\text{TP+FN}}
    \end{equation}
    \begin{itemize}
        \item 전부 True로 판별하면 recall은 항상 $1$
    \end{itemize}
    \item Specificity: Rejected among irrelevant cases; Negative 판별 능력
    \begin{equation}
        \text{specificity}=\frac{\text{FP}}{\text{FP+TN}}
    \end{equation}
    \item Precision: Relevent among selected
    \begin{equation}
        \text{precision}=\frac{\text{TP}}{\text{TP+FP}}
    \end{equation}
    \begin{itemize}
        \item Few elements may cause bad precision
    \end{itemize}
    \item F-score(F$_1$-score): Harmonic mean of precision and recall
    \begin{equation}
        \text{F-score}=\left(\frac{\text{recall}^{-1}+\text{precision}^{-1}}{2}\right)^{-1}
    \end{equation}
    \begin{itemize}
        \item Combines precision and recall
        \item HM averages `rates' $\Rightarrow$ One bad measure causes bad F-score
    \end{itemize}
\end{itemize}

\subsubsection*{Receiver Operating Characteristics (ROC)}
\begin{itemize}
    \item Illustrates the discriminability(제대로 판별하는 능력) of a model
    \item ROC curve plots:
    \begin{equation}
        (\text{FP~rate},\text{TP~rate})=(1-\text{specificity},\text{recall})=\left(\frac{\text{FP}}{\text{TN+FP}},\frac{\text{TP}}{\text{FN+TP}}\right)
    \end{equation}
    \item Ideal point: $(0,1)$ $\Rightarrow$ Closer to $(0,1)$ implies better classifier
    \item ROC curve always goes through $(0,0)$ and $(1,1)$; Classifier must be better than random classifier ($y=x$)
    \item Larger AUC(area under curve) implies better classifier ($\text{AUC}>.8$)
\end{itemize}
\begin{figures}
    \subfig{ROC curve}{roc-curve.png}{.3}
    \subfig{Different ROCs}{roc-diff-curves.png}{.3}
    \subfig{AUC of ROC}{roc-auc.png}{.3}
\end{figures}
