\section{Basic Principles of Probability}

\subsection{Probability and Counting}

\subsubsection*{Probability}
\begin{itemize}
    \item 확률(probability)란 무엇인가?
    \begin{itemize}
        \item Frequentist: 어떤 event가 많이 반복되었을 때 발생한 빈도
        \item Bayesian: 어떤 event가 반복되는 것이 불가능하더라도 발생할 믿음의 정도
    \end{itemize}
    \item Event는 set theory에 의해서 정의될 수 있음
    \item Probability assigns a number to an event
\end{itemize}

\subsubsection*{Sample Space and Event}
\begin{itemize}
    \item Sample space $S$ of an experiment: Set of all possible outcomes $\omega\in S$
    \item Event $A$: Subset of $S$, i.e. $A\subset S$
    \item If actual outcome is in $A$, we say ``$A$ occurred''
    \item 집합 연산을 이용하여 모든 event의 조합 표현 가능, event에 대한 해석 가능
\end{itemize}

\subsubsection*{Set Theory}
\begin{itemize}
    \item Any set operation is composition of two elementary operations
    \begin{itemize}
        \item Union of $A$ and $B$: $A\cup B$ $\iff$ $x\in A$ and $x\in B$
        \item Complement of $A$: $A^c$ $\iff$ $x\in\Omega$ and $x\notin A$
    \end{itemize}
    \item Other compositions can be expressed by elementary operations
    \begin{itemize}
        \item Intersection of $A$ and $B$: $A\cap B=(A^c\cap B^c)^c$
        \item Difference of $A$ and $B$: $A-B=A\cap B^c$
    \end{itemize}
    \item Logical relations between events $A$ and $B$
    \begin{itemize}
        \item Disjoint($A\cap B=\emptyset$): $A$ and $B$ are mutually exclusive
        \item Subset($A\subset B$): $A$ implies $B$
        \item Equal($A=B$): $A$ is equivalent to $B$
    \end{itemize}
\end{itemize}

\subsubsection*{Counting Number of Outcomes}
\begin{itemize}
    \item \# of outcomes of a compound(independent) experiment of two experiment $A$ and $B$ is $\abs{A}\abs{B}$
    \item Making $k$ choices from $n$ objects once at a time
    \begin{itemize}
        \item Sampling \textit{with} replacement: $n^k$ possible outcomes
        \item Sapmling \textit{without} replacement: $\frac{n!}{(n-k)!}$ possible outcomes
    \end{itemize}
\end{itemize}
\clearpage

\subsubsection*{Definition of Probability}
\begin{itemize}
    \item Na\"ive Definition of Probability
    \begin{itemize}
        \item $A$: Event for an experiment with a finite sample space $S$; The na\"ive probability of $A$ is
        \begin{equation}
            P(A)=\frac{\abs{A}}{\abs{S}}
        \end{equation}
        \item Only works for finite $S$ and \textit{equal likelihood} for each outcome
    \end{itemize}
    \item General(Non-na\"ive) Definition of Probability
    \begin{itemize}
        \item Probability space: Sample space $S$ and Probability function $P$
        \item Probability function $P$: Event $A\subset S$ $\to$ $\mathbb{R}^+\cup\{0\}$ and satisfies
        \begin{itemize}
            \item Unit measure: $P(S)=1$
            \item Sigma-additivity: $\forall A_i\subset S$(finite/countable) s.t. $\dot\bigcup_{i=1}^\infty A_i$, $P\left(\dot\bigcup_{i=1}^\infty A_i\right)=\sum_{i=1}^\infty P(A_i)$
        \end{itemize}
        \item $P(\emptyset)=0$ and $P(A)\in[0,1]$
    \end{itemize}
\end{itemize}

\subsubsection*{Properties of Probability}
\begin{itemize}
    \item Properties
    \begin{itemize}
        \item $P(A^c)=1-P(A)$
        \item $A\subset B$ $\implies$ $P(A)\leq P(B)$
        \item $P(A\cup B)=P(A)+P(B)-P(A\cap B)$
    \end{itemize}
    \item Incursion-exclusion
    \begin{equation}
        P\left(\bigcup_{i=1}^nA_i\right)=\sum_iP(A_i)-\sum_{i<j}P(A_i\cap A_j)+\sum_{i<j<k}P(A_i\cap A_j\cap A_k)-\cdots+(-1)^{n+1}P\left(\bigcap_{i=1}^nA_i\right)
    \end{equation}
\end{itemize}

\subsection{Conditional Probability}

\subsubsection*{Conditional Probability}
\begin{itemize}
    \item \textbf{Def.} For events $A$, $B$ with $P(B)>0$, probability of $A$ given $B$, $P(A\mid B)$ is
    \begin{equation}\label{eq:prp:cond-prob}
        P(A\mid B):=\frac{P(A\cap B)}{P(B)}~~(P(B)>0)
    \end{equation}
    \item $P(A)$: prior probability
    \item $P(B)$: evidence probability
    \item $P(A\mid B)$: posterior probability
\end{itemize}

\subsubsection*{Bayes' Rule}
\begin{itemize}
    \item $P(A_1,A_2,\cdots,A_n):=P(A_1\cap A_2\cap\cdots A_n)$
    \item For any events $A$, $B$ with $P(A)>0$ and $P(B)>0$,
    \begin{equation}\label{eq:prp:cond-prob-both-sides}
        P(B)P(A\mid B)=P(A\cap B)=P(A)P(B\mid A)
    \end{equation}
    \begin{itemize}
        \item Derived from \ref{eq:prp:cond-prob}
    \end{itemize}
    \item For any events with $A_1,A_2,\cdots,A_n$ s.t. $P(A_i)>0$,
    \begin{equation}
        P(A_1,A_2,\cdots,A_n)=P(A_1)P(A_2\mid A_1)P(A_3\mid A_1,A_2)\cdots P(A_n\mid A_1,\cdots,A_{n-1})
    \end{equation}
    \item Bayes' Rule: Derived from \ref{eq:prp:cond-prob-both-sides}
    \begin{equation}\label{eq:prp:bayes-rule}
        P(A\mid B)=\frac{P(B\mid A)P(A)}{P(B)}
    \end{equation}
\end{itemize}

\subsubsection*{Law of total probability (LOTP)}
\begin{itemize}
    \item Let $A_1,A_2,\cdots,A_n$ be a partition of the sample space $S$, i.e. $S=\dot{\bigcup}_{i=1}^nA_i$, then
    \begin{equation}
        P(B)=\sum_{i=1}^nP(B\cap A_i)=\sum_{i=1}^nP(B\mid A_i)P(A_i)
    \end{equation}
    \item For an event $A\subset S$,
    \begin{equation}
        P(B)=P(B\mid A)P(A)+P(B\mid A^c)P(A^c)
    \end{equation}
\end{itemize}

\subsubsection*{Conditional Probability and Likelihood Function}
\begin{itemize}
    \item For a given event $E\subset S$ with $P(E)>0$,
    \item $P(\cdot\mid E)$ is a probability function
    \begin{itemize}
        \item $\because$ $P(S\mid E)=1$ and satisfies LOTP.
        \item $P(A^c\mid E)=1-P(A\mid E)$, $P(\emptyset\mid E)=0$, $P(A\cup B\mid E)=P(A\mid E)+P(B\mid E)-P(A\cap B\mid E)$
    \end{itemize}
    \item $P(E\mid\cdot)$ is NOT a probability function; Instead, a ``likelihood function''
    \begin{itemize}
        \item $P(E\mid\emptyset)$ cannot be defined, $P(E\mid S)=P(E)\neq 1$
    \end{itemize}
\end{itemize}

\subsubsection*{Extra Conditioning}
\begin{itemize}
    \item Bayes' rule w/ extra conditioning: $P(A\cap E)>0$ and $P(B\cap E)>0$, then
    \begin{equation}
        P(A\mid B,E)=\frac{P(B\mid A,E)P(A\mid E)}{P(B\mid E)}
    \end{equation}
    \begin{itemize}
        \item \ref{eq:prp:bayes-rule} is when $E=S$
    \end{itemize}
    \item LOTP w/ extra conditioning: For $A_i$ s.t. $S=\dot{\bigcup}_{i=1}^nA_i$ and $P(A_i\cap E)>0$,
    \begin{equation}
        P(B\mid E)=\sum_{i=1}^nP(B\mid A_i,E)P(A_i\mid E)
    \end{equation}
\end{itemize}

\subsubsection*{Independence}
\begin{itemize}
    \item \textbf{Def.} Events $A$ and $B$ are independent if
    \begin{equation}
        P(A\cap B)=P(A)P(B)
    \end{equation}
    \begin{itemize}
        \item Notation: $A\indep B$
        \item $A\indep B$ $\implies$ $P(A\mid B)=P(A)$, $P(B\mid A)=P(B)$
        \item Mutually exclusive events ($A\cap B=\emptyset$) DOES NOT imply independence
        \item Mutually exclusive: $P(A\mid B)=0$, Equal: $P(A\mid B)=1$, Independent: $P(A\mid B)=P(A)$
    \end{itemize}
    \item $A\indep B$ $\implies$ $A^c\indep B$, $A\indep B^c$, $A^c\indep B^c$
    \item \textbf{Def.} Independence of many events: $n$ events $A_1,A_2,\cdots,A_n$ are independent if
    \begin{equation}
        \forall~\{i_1,\cdots,i_k\}\subset\{1,\cdots,n\},~P\left(\bigcap_{j=1}^kA_{i_j}\right)=\prod_{j=1}^kP(A_{i_j})
    \end{equation}
    \item \textbf{Def.} Conditional indep.: Events $A$, $B$: cond. indep. given $E$ if
    \begin{equation}
        P(A\cap B\mid E)=P(A\mid E)P(B\mid E)
    \end{equation}
    \begin{itemize}
        \item Notation: $A\indep B\mid E$
        \item Pairwise independence (e.g. $A$-$B$, $B$-$C$, $C$-$A$) $\centernot\implies$ Independence
        \item Conditional Independence $\centernot\iff$ Independence
    \end{itemize}
\end{itemize}
